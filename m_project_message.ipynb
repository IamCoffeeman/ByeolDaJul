{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seunghyeokkim/ByeolDaJul/blob/main/m_project_message.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-JA7xmtaIgj"
      },
      "source": [
        "### pip install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-cMKrBrAaIgk"
      },
      "outputs": [],
      "source": [
        "pip install konlpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "prflXvZJaIgl"
      },
      "outputs": [],
      "source": [
        "pip install pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GTeq_ppLaIgl"
      },
      "outputs": [],
      "source": [
        "pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9dpT_wqpaIgm"
      },
      "outputs": [],
      "source": [
        "pip install tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NurRGNjhaIgm"
      },
      "outputs": [],
      "source": [
        "pip install scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EHOrNmt7aIgm"
      },
      "outputs": [],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6BTBLE8UaIgm",
        "outputId": "91e7f104-24ff-4807-b23a-4f425b0c37f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in c:\\users\\user\\anaconda3\\envs\\mecab_env\\lib\\site-packages (1.13.1)\n",
            "Requirement already satisfied: typing-extensions in c:\\users\\user\\anaconda3\\envs\\mecab_env\\lib\\site-packages (from torch) (4.7.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUI5UtgzaIgn"
      },
      "source": [
        "### Data_Preparing & Train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kUJZVPxQaIgn"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from datetime import datetime\n",
        "import json\n",
        "import re\n",
        "\n",
        "from konlpy.tag import Okt # komoran, han, kkma\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from transformers import BertTokenizer, TFBertModel\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "from konlpy.tag import Mecab\n",
        "mecab = Mecab(dicpath=r\"C:/mecab/mecab-ko-dic\") # BERT에서 Mecab은 안써요.."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uzevNesyaIgo",
        "outputId": "01a39c30-acb0-4433-b58c-fc4ac4202af6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>intent_pair1</th>\n",
              "      <th>intent_pair2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>이번 주에 기온변화가 가장 큰 요일을 알려줘</td>\n",
              "      <td>이번 주 기온변화 가장 큰 요일</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>공기청정기 켜져있니</td>\n",
              "      <td>공기청정기 켜졌는지</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>오늘 오후에 수영대회가 있니</td>\n",
              "      <td>오늘 오후 수영대회 여부</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>가급적 아이리버 엠피쓰리는 사지 않도록 합시다</td>\n",
              "      <td>아이리버 엠피쓰리 사지 않기</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>전체 메일을 쓸 때 민감한 내용은 쓰지마</td>\n",
              "      <td>민감한 내용 전체메일 보내지 않기</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50832</th>\n",
              "      <td>2</td>\n",
              "      <td>청포묵과 우묵가사리는 대체 뭐가 다른거니</td>\n",
              "      <td>청포묵과 우묵가사리의 차이</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50833</th>\n",
              "      <td>2</td>\n",
              "      <td>역사에서 협상으로 전쟁을 대신한 사례가 뭐가 있지</td>\n",
              "      <td>전쟁을 협상으로 대처한 사례</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50834</th>\n",
              "      <td>4</td>\n",
              "      <td>거실 조명 하나만 꺼 줘</td>\n",
              "      <td>거실 조명 하나만 끄기</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50835</th>\n",
              "      <td>0</td>\n",
              "      <td>내게 쓴 메일함 다 비웠니</td>\n",
              "      <td>내게 쓴 메일함 다 비웠는지</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50836</th>\n",
              "      <td>4</td>\n",
              "      <td>이번주 목요일 할머니 칠순잔치 일정 추가해줘</td>\n",
              "      <td>이번주 목요일 할머니 칠순잔치 일정 추가하기</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>50837 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       label                  intent_pair1              intent_pair2\n",
              "0          2      이번 주에 기온변화가 가장 큰 요일을 알려줘         이번 주 기온변화 가장 큰 요일\n",
              "1          0                    공기청정기 켜져있니                공기청정기 켜졌는지\n",
              "2          0               오늘 오후에 수영대회가 있니             오늘 오후 수영대회 여부\n",
              "3          3    가급적 아이리버 엠피쓰리는 사지 않도록 합시다            아이리버 엠피쓰리 사지 않기\n",
              "4          3        전체 메일을 쓸 때 민감한 내용은 쓰지마        민감한 내용 전체메일 보내지 않기\n",
              "...      ...                           ...                       ...\n",
              "50832      2       청포묵과 우묵가사리는 대체 뭐가 다른거니             청포묵과 우묵가사리의 차이\n",
              "50833      2  역사에서 협상으로 전쟁을 대신한 사례가 뭐가 있지            전쟁을 협상으로 대처한 사례\n",
              "50834      4                 거실 조명 하나만 꺼 줘              거실 조명 하나만 끄기\n",
              "50835      0                내게 쓴 메일함 다 비웠니           내게 쓴 메일함 다 비웠는지\n",
              "50836      4      이번주 목요일 할머니 칠순잔치 일정 추가해줘  이번주 목요일 할머니 칠순잔치 일정 추가하기\n",
              "\n",
              "[50837 rows x 3 columns]"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 데이터 불러오기\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "data_df = pd.read_csv('C:/Users/user/Desktop/m_project_message/sae4k_v2.csv', sep = '\\t', names = ['label', 'intent_pair1', 'intent_pair2'], header=None)\n",
        "data_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rBcH53PjaIgo"
      },
      "outputs": [],
      "source": [
        "# 중복 행 제거\n",
        "data_df.drop_duplicates(subset=['intent_pair1'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gG4ybrm5aIgo"
      },
      "outputs": [],
      "source": [
        "# Train/test data split\n",
        "X = data_df['intent_pair1']\n",
        "y = data_df['label']\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42) #분할 비율 80 10 10\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "on-k3a0_aIgo"
      },
      "source": [
        "### Tokenizer를 이용한 인코딩"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tSXoJD_BaIgo"
      },
      "outputs": [],
      "source": [
        "# AutoConfig 클래스, 사전 훈련된 모델의 설정 정보 로드\n",
        "from transformers import AutoConfig\n",
        "# from_pretrained 메서드를 사용하여 모델 설정 정보 로드\n",
        "config = AutoConfig.from_pretrained(\"klue/bert-base\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tWHeA7CMaIgp"
      },
      "outputs": [],
      "source": [
        "# 모델 토크나이징 및 설정 관리 하는 클래스 호출\n",
        "from transformers import BertTokenizerFast, BertModel, AutoTokenizer\n",
        "\n",
        "# klue/bert-base 모델의 토크나이저를 로드\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"klue/bert-base\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S7pOvvIsaIgp",
        "outputId": "b488fc23-1823-4d8d-be16-3e26aa28e576"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((39123,), (4891,))"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape, X_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wy_UxVmdaIgp"
      },
      "outputs": [],
      "source": [
        "# 리스트로 변경\n",
        "X_train_list = X_train.tolist()\n",
        "X_test_list = X_test.tolist()\n",
        "y_train = y_train.tolist()\n",
        "y_test = y_test.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RC-H2zt_aIgp"
      },
      "outputs": [],
      "source": [
        "# tokenizer을 사용하여 텍스트 데이터를 모델 입력으로 변환, truncation=True (문장이 모델의 최대 길이 초과 시 자른다), return_tensors\n",
        "X_train = tokenizer(X_train_list, truncation=True, padding=True, return_tensors = 'tf')\n",
        "X_test = tokenizer(X_test_list, truncation=True, padding=True, return_tensors = 'tf')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fv7DFCUUaIgp"
      },
      "source": [
        "### Model 생성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-vtGYjUJaIgp"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# 주어진 데이터소스를 여러 Tensor로 자른 후 iterator(반복가능 객체)로 만들기\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    dict(X_train),\n",
        "    y_train\n",
        "))\n",
        "\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    dict(X_test),\n",
        "    y_test\n",
        "))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P37m1OClaIgp"
      },
      "outputs": [],
      "source": [
        "# BERT 모델을 활용한 텍스트 분류 모델을 정의하는 Python 클래스\n",
        "import tensorflow as tf\n",
        "class MyModel(tf.keras.Model):\n",
        "    def __init__(self, model_name):\n",
        "        super().__init__()\n",
        "        # BERT 모델 로드, from_pt = True -> PyTorch 모델 TensorFlow 변환\n",
        "        self.bert = TFBertModel.from_pretrained(model_name, from_pt=True)\n",
        "        # 분류 작업을 위한 Dense Layer 생성, 6개의 클래스로 분류하도록 구성\n",
        "        self.classifier = tf.keras.layers.Dense(6,\n",
        "                                                kernel_initializer=tf.keras.initializers.TruncatedNormal(0.02),\n",
        "                                                activation='softmax',\n",
        "                                                name='classifier')\n",
        "\n",
        "    def call(self, input_ids = None, attention_mask=None, token_type_ids=None): # 선언되어 있는 객체 호출\n",
        "        # input_ids, attention_mask, token_type_ids = inputs\n",
        "        # BERT 모델에 입력 데이터를 전달하여 출력을 얻는다.\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
        "        # BERT 출력 중 [CLS] 토큰 벡터 선택\n",
        "        cls_token = outputs[1]\n",
        "        prediction = self.classifier(cls_token)\n",
        "\n",
        "        return prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gMFFgXWcaIgq",
        "outputId": "336e3637-c421-4ae8-fce7-c4a74fd66e47"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'bert.embeddings.position_ids', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "model = MyModel(\"klue/bert-base\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cgAVd6eQaIgq"
      },
      "outputs": [],
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=loss, metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJrD0Yn6aIgq"
      },
      "source": [
        "### Model 학습"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sy2FtkEKaIgq"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "# 성능 개선이 0.001 미만이면 종료, patience 2회\n",
        "callback_earlystop = EarlyStopping(\n",
        "    monitor=\"val_accuracy\",\n",
        "    min_delta=0.001,\n",
        "    patience=2)\n",
        "# 모델 학습시키는 메서드, 검증과 학습 데이터셋 각각 섞은 후 배치크기 32\n",
        "model.fit(\n",
        "    train_dataset.shuffle(len(train_dataset)).batch(32), # batch 단위로 잘라서 학습\n",
        "    epochs=1, batch_size=32,\n",
        "    validation_data = val_dataset.shuffle(len(val_dataset)).batch(32),\n",
        "    callbacks = [callback_earlystop]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZirMoQxaIgq"
      },
      "source": [
        "### 결과 출력 & 저장"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xxCiv3LfaIgq"
      },
      "outputs": [],
      "source": [
        "# label 0 : \"yes/no\",\n",
        "# label 1 : \"alternative\",\n",
        "# label 2 : \"wh- questions\",\n",
        "# label 3 : \"prohibitions\",\n",
        "# label 4 : \"requirements\",\n",
        "# label 5 : \"strong requirements\","
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fYzDvhcNaIgq",
        "outputId": "fe5e3cc5-0b8e-4785-ca1f-33eccfc852d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'sentence': '오늘은 공부하지말고 놀자', 'label': 'strong requirements'}\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# 입력 문장\n",
        "text = '오늘은 공부하지말고 놀자'\n",
        "\n",
        "# 모델에 입력 전처리\n",
        "inputs = tokenizer(text, return_tensors=\"tf\")\n",
        "\n",
        "# 모델 예측\n",
        "output = model(**inputs)\n",
        "\n",
        "# 클래스 라벨 및 예측 확률\n",
        "class_labels = [\"yes/no\", \"alternative\", \"wh- questions\", \"prohibitions\", \"requirements\", \"strong requirements\"]\n",
        "predicted_label = np.argmax(output, axis=1)\n",
        "predicted_probabilities = output.numpy()\n",
        "\n",
        "# 결과를 dictionary 형식으로 출력\n",
        "result = {\n",
        "    \"sentence\": text,\n",
        "    \"label\": class_labels[predicted_label[0]]\n",
        "}\n",
        "\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "72a6bSRpaIgq"
      },
      "outputs": [],
      "source": [
        "# 전체 데이터를 라벨링하는 코드\n",
        "data = []\n",
        "for i in range(len(data_df['intent_pair1'])):\n",
        "    if i not in data_df.index:\n",
        "        continue\n",
        "\n",
        "    text = data_df['intent_pair1'][i]\n",
        "\n",
        "    inputs = tokenizer(text, return_tensors=\"tf\")\n",
        "\n",
        "    output = model(**inputs)\n",
        "\n",
        "    # class_labels = [\"yes/no\", \"alternative\", \"wh- questions\", \"prohibitions\", \"requirements\", \"strong requirements\"]\n",
        "    class_labels = [0, 1, 2, 3, 4, 5]\n",
        "\n",
        "    predicted_label = np.argmax(output, axis=1)\n",
        "\n",
        "    result = {\n",
        "        \"sentence\": text,\n",
        "        \"label\": class_labels[predicted_label[0]]\n",
        "    }\n",
        "\n",
        "    data.append(result)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G97ivv6XaIgq",
        "outputId": "582aab7a-ceaf-48e2-ecf8-c0d2b4d36ebf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "텍스트 파일이 성공적으로 저장되었습니다.\n"
          ]
        }
      ],
      "source": [
        "# 텍스트 파일 경로\n",
        "txt_file_path = \"C:/Users/user/Desktop/m_project_message/data.txt\"\n",
        "\n",
        "# 텍스트 파일로 데이터 저장\n",
        "with open(txt_file_path, \"w\") as txt_file:\n",
        "    for item in data:\n",
        "        txt_file.write(f\"{item}\\n\")\n",
        "\n",
        "print(\"텍스트 파일이 성공적으로 저장되었습니다.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtZ79Te1aIgr"
      },
      "source": [
        "### Weight 개수 확인"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7vwRDjHPaIgr"
      },
      "outputs": [],
      "source": [
        "total_params = 0\n",
        "for layer in model.layers:\n",
        "    total_params += np.sum([np.prod(w.shape) for w in layer.weights])\n",
        "\n",
        "print(f\"Total number of weights in the model: {total_params}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "mecab_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.16"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}