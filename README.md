**프로젝트 : 별다줄**

![1표지](https://github.com/seunghyeokkim/ByeolDaJul/assets/140465121/b1cfbf83-40d1-489e-b11b-3adf3e09c51a)

진행 단체 및 목적 : KDP 4기 , 미니프로젝트

프로젝트 기간 : 2023.08 ~ 2023.09

---

**1. 프로젝트 소개**

![2](https://github.com/seunghyeokkim/ByeolDaJul/assets/140465121/9fabd142-756b-4934-b2d3-078e5c67b446)

- 메시지 수신 내용을 5단어 이내의 짧은 문장으로 변환하는 기능 개발

- 메시지를 읽기 바쁜 상황일때, 아주 간단한 미리보기를 제공함으로서 편리함을 얻을 수 있을거란 아이디어에서 착안

---

**2. 시작 가이드**

설치 및 실행방법

- GPU 할당 후 전체 코드 실행

---

**3. 기술 스택**

[![stackticon](https://firebasestorage.googleapis.com/v0/b/stackticon-81399.appspot.com/o/images%2F1710902914472?alt=media&token=30fa6a40-b6d7-460a-89b6-8e9d50194703)](https://github.com/msdio/stackticon)

---

**4. 아키텍쳐 및 시나리오**

![3](https://github.com/seunghyeokkim/ByeolDaJul/assets/140465121/811153af-a7cb-402d-bb1a-c7fbd8c85009)

![4](https://github.com/seunghyeokkim/ByeolDaJul/assets/140465121/2d688c46-a4f4-4a88-92e4-2f3e5efa05c5)

![9](https://github.com/seunghyeokkim/ByeolDaJul/assets/140465121/1ebff8a5-0e8f-4c27-ba0e-d974b3f3e687)

---

**5. 사용 데이터**

![5](https://github.com/seunghyeokkim/ByeolDaJul/assets/140465121/6489bc6e-0a24-4270-963f-51f4d55d7814)

---

**6. 사용 모델**

- LSTM , Attention , BERT fine-tuning

- Koalphaca

![8](https://github.com/seunghyeokkim/ByeolDaJul/assets/140465121/c8fb7120-e39e-4886-ae6d-9ebebadfb22a)

---

**7. 결과 요약**

![10](https://github.com/seunghyeokkim/ByeolDaJul/assets/140465121/ab163615-092c-44ae-8f74-d6bef07758a1)

![11](https://github.com/seunghyeokkim/ByeolDaJul/assets/140465121/8848bb24-a968-40c8-886c-5804f6bda5a3)

![12](https://github.com/seunghyeokkim/ByeolDaJul/assets/140465121/acff9d6f-c717-47e5-b56d-fffaa2388f65)
